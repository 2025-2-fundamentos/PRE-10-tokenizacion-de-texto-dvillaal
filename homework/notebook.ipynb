{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e2c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  It is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  Electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt  Global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "import glob\n",
    "\n",
    "def load_data(input_directory):\n",
    "\n",
    "    sequence = []\n",
    "    files = glob.glob(f\"{input_directory}/*\")\n",
    "    for file in files:\n",
    "        with open(file, \"rt\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "            sequence.append((file, raw_text))\n",
    "    return sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "for file, text in sequence:\n",
    "    print(f\"{file}  {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f856a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "import re\n",
    "\n",
    "def clean_text(sequence):\n",
    "    cleaned_sequence = []\n",
    "    for file, text in sequence:\n",
    "        cleaned_text = re.sub(r\"\\n\", \" \", text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        cleaned_sequence.append((file, cleaned_text))\n",
    "    return cleaned_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "for file, text in cleaned_sequence:\n",
    "    print(f\"{file}  {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c582020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non-precious metal-based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "def tokenize(sequence):\n",
    "    tokenized_sequence = []\n",
    "    for file, text in sequence:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokenized_sequence.append((file, tokens))\n",
    "    return tokenized_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db35b4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop alternatives used in hydrogen evolution reaction\n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately and along with it ef\n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to deter\n"
     ]
    }
   ],
   "source": [
    "# Remoción de datos ruidosos (Opcion A)\n",
    "def filter_tokens_a(sequence):\n",
    "    \"\"\"Esta solucion puede perder tokens que contienen caracteres no alfabeticos\"\"\"\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token.isalpha()]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_a(tokenized_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:75]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bac700b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is essential to develop alternatives used in hydrogen evolution\n",
      "reaction her due to high cost and scarcity of catalysts herein through\n",
      "density functional theory dft calculations the her activity over\n",
      "anchored phosphorus carbide monolayer tm has been systematically\n",
      "investigated results indicate that δg h of v fe nb mo and pd are lower\n",
      "than that of pt catalyst with and ev respectively by imposing the\n",
      "criterion window δg h ev the d band centre εd for catalysts with\n",
      "excellent her ability is in the range of ev besides the five promising\n",
      "her catalysts follow mechanism fe nb and mo show activation barriers\n",
      "of and ev lower than that of pt machine learning ml was employed to\n",
      "explore the intrinsic relationship between catalytic performance and\n",
      "feature parameters we demonstrated that the first ionization energy\n",
      "bond length of tm h and d band center are more correlated with\n",
      "hydrogen adsorption behaviour our work not only predicts that fe nb\n",
      "and mo can be substitutes for pt metal in her but also reveals that\n",
      "the intrinsic correlation between catalytic activity and feature\n",
      "parameters by combining dft and ml investigations\n",
      "\n",
      "\n",
      "electric vehicles are gaining global popularity lately and along with\n",
      "it efficient battery thermal management systems btms are also gaining\n",
      "traction amongst the research community phase change material pcm\n",
      "based btms can be an attractive solution due to its high energy\n",
      "density and isothermal energy exchange however pure pcm has some\n",
      "drawbacks like low thermal conductivity volume expansion and leakage\n",
      "during phase change a shape stable composite pcm sscpcm resolves these\n",
      "drawbacks but is an expensive solution due to the high cost of\n",
      "conventional supporting materials biochar bc based sscpcm developed in\n",
      "this study can be a cheap and sustainable solution for btms the\n",
      "characterization studies are carried out for combination of pure pcm\n",
      "myristyl alcohol and biochar at various loadings of and by weight\n",
      "using fourier transform infrared analysis diffraction xrd analysis\n",
      "scanning electron microscopy sem particle size analysis psa\n",
      "differential scanning calorimetry dsc and thermogravimetric analysis\n",
      "tga the shape stability studies reveal that the pcm with minimum of\n",
      "biochar is shape stable the thermal conductivities and effusivities of\n",
      "pure and composite pcms are also studied enhancement in thermal\n",
      "conductivity of is studied with the addition of carbon nanotubes mwcnt\n",
      "in and concentrations and xrd results reveal that the interaction of\n",
      "biochar and mwcnt with pure pcm is purely physical and chemically\n",
      "stable the degree of supercooling is reduced by and for with mwcnt\n",
      "compared to pure pcm at a heating rate of and respectively thermal\n",
      "conductivity and effusivity of with mwcnt are and higher than the pure\n",
      "pcm respectively the tga results reveal that pcms thermal stability is\n",
      "not adversely affected by the addition of bc mwcnt furthermore an\n",
      "anfis model is developed to predict the heat flow values of pcm\n",
      "samples and found that the generalized input and linear output\n",
      "membership function is best suitable with a coefficient of\n",
      "determination of\n",
      "\n",
      "\n",
      "global solar irradiation is an important variable that can be used to\n",
      "determine the suitability of an area to install solar systems\n",
      "nevertheless due to the limitations of requiring measurement stations\n",
      "around the entire world it can be correlated with different\n",
      "meteorological parameters to confront this issue different locations\n",
      "in rias baixas autonomous community of galicia spain and combinations\n",
      "of parameters month and average temperature among others were used to\n",
      "develop various machine learning models random forest support vector\n",
      "machine and artificial neural network these three approaches were used\n",
      "to model and predict one month ahead monthly global solar irradiation\n",
      "using the data from six measurement stations afterwards these models\n",
      "were applied to seven different measurement stations to check if the\n",
      "knowledge acquired could be extrapolated to other locations in general\n",
      "the ann models offered the best results for the development and\n",
      "testing phases of the model as well as for the phase of knowledge\n",
      "extrapolation to other locations in this sense the selected anns\n",
      "obtained a mean absolute percentage error mape value between and for\n",
      "the model development and an overall mape between and for the other\n",
      "seven locations anns can be a capable tool for modelling and\n",
      "predicting monthly global solar irradiation in areas where data are\n",
      "available and for extrapolating this knowledge to nearby areas\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for file, text in filtered_sequence:\n",
    "    print(textwrap.fill(' '.join(text)))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c0707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  it is essential to develop non precious metal based alternatives used \n",
      "../files/input\\file2.txt  electric vehicles are gaining global popularity lately and along with \n",
      "../files/input\\file3.txt  global solar irradiation is an important variable that can be used to \n"
     ]
    }
   ],
   "source": [
    "# Remoción de datos ruidosos (Opcion B)\n",
    "def filter_tokens_b(sequence):\n",
    "    \"\"\"Esta solucion puede perder tokens que contienen caracteres no alfabeticos\"\"\"\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [re.sub(r\"[^a-zA-Z\\s]\", \" \", token) for token in tokens]\n",
    "        filtered_tokens = [re.sub(r\"\\s+\", \" \", token) for token in filtered_tokens]\n",
    "        filtered_tokens = [token.strip() for token in filtered_tokens]\n",
    "        filtered_tokens = [token for token in filtered_tokens if token != \"\"]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "  \n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "\n",
    "\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2e3f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input\\file1.txt  essential develop non precious metal based alternatives used hydrogen \n",
      "../files/input\\file2.txt  electric vehicles gaining global popularity lately along efficient bat\n",
      "../files/input\\file3.txt  global solar irradiation important variable used determine suitability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USUARIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove the stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def remove_stopwords(sequence):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44df0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "\n",
    "def save_data(output_directory, sequence):\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for file, tokens in sequence:\n",
    "        file = file.replace(\"\\\\\", \"/\")\n",
    "        with open(\n",
    "            f\"{output_directory}/{file.split('/')[-1]}\",\n",
    "            \"wt\",\n",
    "            encoding=\"utf-8\",\n",
    "        ) as f:\n",
    "            f.write(textwrap.fill(\" \".join(tokens), width=70))\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "save_data(output_directory=\"../files/output\", sequence=filtered_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
